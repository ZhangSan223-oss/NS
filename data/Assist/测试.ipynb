{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f709bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学生索引  min = 1  max = 4163\n",
      "题目索引  min = 1  max = 17746\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib\n",
    "\n",
    "data = json.loads(pathlib.Path('log_data.json').read_text())   # 把文件名换成你的\n",
    "\n",
    "# 收集所有 user_id 与 exer_id\n",
    "user_ids = [item['user_id'] for item in data]\n",
    "exer_ids = [log['exer_id'] for item in data for log in item['logs']]\n",
    "\n",
    "print('学生索引  min =', min(user_ids), ' max =', max(user_ids))\n",
    "print('题目索引  min =', min(exer_ids), ' max =', max(exer_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8604d3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学生索引  min = 1  max = 4128\n",
      "题目索引  min = 1  max = 17746\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib\n",
    "\n",
    "data = json.loads(pathlib.Path('train_set.json').read_text())   # 把文件名换成你的\n",
    "\n",
    "# 收集所有 user_id 与 exer_id\n",
    "user_ids = [item['user_id'] for item in data]\n",
    "exer_ids = [item['exer_id'] for item in data]\n",
    "\n",
    "print('学生索引  min =', min(user_ids), ' max =', max(user_ids))\n",
    "print('题目索引  min =', min(exer_ids), ' max =', max(exer_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc1b745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "知识点数量： 122\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def count_unique_knowledge_codes(json_file: str | Path) -> int:\n",
    "    \"\"\"\n",
    "    统计 JSON 文件中不重复的知识点（knowledge_code）数量。\n",
    "    \n",
    "    参数\n",
    "    ----\n",
    "    json_file : str | pathlib.Path\n",
    "        待读取的 JSON 文件路径。\n",
    "    \n",
    "    返回\n",
    "    ----\n",
    "    int\n",
    "        不重复的知识点数量。\n",
    "    \"\"\"\n",
    "    # 读取 JSON\n",
    "    with open(json_file, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 用 set 去重\n",
    "    codes = set()\n",
    "    for record in data:\n",
    "        # 兼容 knowledge_code 可能是单 int 或 list[int] 的情况\n",
    "        kc = record.get(\"knowledge_code\", [])\n",
    "        if isinstance(kc, int):\n",
    "            codes.add(kc)\n",
    "        else:\n",
    "            codes.update(kc)\n",
    "\n",
    "    return len(codes)\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    json_path = \"train_set.json\"  # 替换为你的文件路径\n",
    "    print(\"知识点数量：\", count_unique_knowledge_codes(json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0350d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "知识点数量： 122\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def count_unique_kcs(json_file: str | Path) -> int:\n",
    "    with open(json_file, encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    codes = set()\n",
    "    for rec in data:\n",
    "        kc = rec.get(\"knowledge_code\", [])\n",
    "        if isinstance(kc, int):\n",
    "            codes.add(kc)\n",
    "        else:\n",
    "            codes.update(kc)\n",
    "    return len(codes)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"知识点数量：\", count_unique_kcs(\"train_set.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c882fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "知识点数量： 123\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def count_unique_knowledge_codes_nested(json_file: str | Path) -> int:\n",
    "    \"\"\"\n",
    "    统计嵌套 JSON 中所有 logs 里不重复的知识点（knowledge_code）数量。\n",
    "    顶层为列表，每项含 logs 列表。\n",
    "    \"\"\"\n",
    "    with open(json_file, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    codes = set()\n",
    "    for top_item in data:          # 遍历顶层列表\n",
    "        for log in top_item.get(\"logs\", []):\n",
    "            kc = log.get(\"knowledge_code\", [])\n",
    "            if isinstance(kc, int):\n",
    "                codes.add(kc)\n",
    "            else:\n",
    "                codes.update(kc)\n",
    "    return len(codes)\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    json_path = \"test_set.json\"  # 替换为你的文件路径\n",
    "    print(\"知识点数量：\", count_unique_knowledge_codes_nested(json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c6e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 矩阵维度： (17746, 123)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def q_matrix_shape(txt_file: str | Path):\n",
    "    \"\"\"\n",
    "    返回 Q 矩阵维度 (n_items, n_kcs)\n",
    "    支持空格/制表符分隔或纯连续 0/1 两种格式\n",
    "    \"\"\"\n",
    "    with open(txt_file, encoding='utf-8') as f:\n",
    "        lines = [ln.rstrip('\\n') for ln in f if ln.strip()]\n",
    "\n",
    "    # 尝试空格/制表符分隔\n",
    "    first_split = lines[0].split()\n",
    "    if len(first_split) > 1:          # 空格分隔\n",
    "        n_items = len(lines)\n",
    "        n_kcs   = len(first_split)\n",
    "    else:                             # 连续 0/1 字符串\n",
    "        n_items = len(lines)\n",
    "        n_kcs   = len(lines[0])\n",
    "        # 简单校验：每行长度应相同\n",
    "        if any(len(ln) != n_kcs for ln in lines):\n",
    "            raise ValueError(\"各行长度不一致，请检查文件格式\")\n",
    "    return n_items, n_kcs\n",
    "\n",
    "\n",
    "# 示例\n",
    "if __name__ == \"__main__\":\n",
    "    txt_path = \"q.txt\"          # 换成你的文件\n",
    "    print(\"Q 矩阵维度：\", q_matrix_shape(txt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fd50ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : 123\n",
      "train_set: 122\n",
      "val_set  : 119\n",
      "test_set : 123\n",
      "union    : 123\n",
      "missing  : set()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_kc_set(file_name):\n",
    "    \"\"\"返回文件里出现过的所有 knowledge_code 编号\"\"\"\n",
    "    kc = set()\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    # 统一处理两种格式：列表扁平化 或 单条 dict\n",
    "    if isinstance(data, list) and data and 'logs' in data[0]:   # train_slice/val/test 格式\n",
    "        for stu in data:\n",
    "            for log in stu['logs']:\n",
    "                kc.update(log['knowledge_code'] if isinstance(log['knowledge_code'], list)\n",
    "                          else [log['knowledge_code']])\n",
    "    else:  # train_set 格式，已经是扁平列表\n",
    "        for rec in data:\n",
    "            kc.update(rec['knowledge_code'] if isinstance(rec['knowledge_code'], list)\n",
    "                      else [rec['knowledge_code']])\n",
    "    return kc\n",
    "original = read_kc_set('log_data.json')\n",
    "train_set = read_kc_set('train_set.json')\n",
    "val_set   = read_kc_set('val_set.json')\n",
    "test_set  = read_kc_set('test_set.json')\n",
    "\n",
    "print('original :', len(original))\n",
    "print('train_set:', len(train_set))\n",
    "print('val_set  :', len(val_set))\n",
    "print('test_set :', len(test_set))\n",
    "print('union    :', len(train_set | val_set | test_set))\n",
    "print('missing  :', original - (train_set | val_set | test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4bd3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总做题记录数: 278868\n",
      "用户数量: 4163\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 读取JSON文件（假设文件名为 data.json）\n",
    "with open('log_data.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 统计所有用户的做题记录总数\n",
    "total_exercises = 0\n",
    "for user in data:\n",
    "    total_exercises += len(user[\"logs\"])\n",
    "\n",
    "print(f\"总做题记录数: {total_exercises}\")\n",
    "print(f\"用户数量: {len(data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
